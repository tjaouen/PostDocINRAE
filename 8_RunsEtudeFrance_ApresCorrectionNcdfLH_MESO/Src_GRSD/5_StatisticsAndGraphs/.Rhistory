### Parallel MPI ###
post = function(x, ...) {
print(paste0(formatC(as.character(rank),
width=3, flag=" "),
"/", size-1, " > ", x), ...)
}
library(Rmpi)
rank = mpi.comm.rank(comm=0)
HER_h_ = 85
tab_allModels_ = data.frame()
tab_1_ <- read.table(list_files_chroniquesProba_[1], sep = ";", dec = ".", header = T)
colnames(tab_1_) <- gsub("X","",colnames(tab_1_))
for (l in 1:length(list_files_chroniquesProba_)){
tab_l_ <- read.table(list_files_chroniquesProba_[l], sep = ";", dec = ".", header = T)
colnames(tab_l_) <- gsub("X","",colnames(tab_l_))
tab_l_ <- tab_l_[,c("Date","Type",HER_h_)]
colnames(tab_l_) <- c("Date","Type",str_after_last(str_before_last(list_files_chroniquesProba_[l],"/"),"/"))
if (ncol(tab_allModels_) == 0){
tab_allModels_ <- tab_l_
}else{
tab_allModels_ <- merge(tab_allModels_, tab_l_, by = c("Date","Type"))
}
}
tab_allModels_$Date <- as.Date(tab_allModels_$Date)
tab_allModels_$Jour_annee <- format(tab_allModels_$Date, format = "%m-%d")
### Selectionner periode ###
tab_allModels_2070_2100_ = tab_allModels_[which(tab_allModels_$Date >= as.Date(date_intervalle_[1]) & tab_allModels_$Date <= as.Date(date_intervalle_[2])),]
if (!(nrow(tab_allModels_2070_2100_[which(tab_allModels_2070_2100_$Type == "Historical"),]) %in% c(as.Date(date_intervalle_[2])-as.Date(date_intervalle_[1])+1,0))){
stop(paste0("Error with Historical content. File :", list_files_chroniquesProba_[l], " - HER : ", HER_h_))
}
if (!(nrow(tab_allModels_2070_2100_[which(tab_allModels_2070_2100_$Type == "Safran"),]) %in% c(as.Date(date_intervalle_[2])-as.Date(date_intervalle_[1])+1,0))){
stop(paste0("Error with Safran content. File :", list_files_chroniquesProba_[l], " - HER : ", HER_h_))
}
if (!(nrow(tab_allModels_2070_2100_[grepl("rcp",tab_allModels_2070_2100_$Type),]) %in% c(as.Date(date_intervalle_[2])-as.Date(date_intervalle_[1])+1,0))){
stop(paste0("Error with rcp content. File :", list_files_chroniquesProba_[l], " - HER : ", HER_h_))
}
nrow(tab_allModels_2070_2100_[grepl("rcp",tab_allModels_2070_2100_$Type),])
c(as.Date(date_intervalle_[2])-as.Date(date_intervalle_[1])+1
as.Date(date_intervalle_[2])-as.Date(date_intervalle_[1])+1
as.Date(date_intervalle_[2])-as.Date(date_intervalle_[1])+1
max(tab_allModels_$Date)
date_intervalle_
### Programmes ###
source("/home/tjaouen/Documents/Src/PathsProgram/PathProgram_1_20230206.R")
source("/home/tjaouen/Documents/Src/ChangementClimatique_Bottet2019/CodesTristan/8_RunsEtudeFrance_ApresCorrectionNcdfLH/1_Parameters/0_SimulationParameters_AvecCC_2_20230227.R")
### Libraries ###
library(ggplot2)
library(readxl)
require(maptools)
library(rgdal)
library(maps)
library(mapdata)
library(dplyr)
library(rgeos)
library(RColorBrewer)
library(fields)
library(scales)
library(strex)
library(gridExtra)
library(ggrepel)
library(sp)
library(rgdal)
library(sf)
library(ggspatial)
library(tidyverse)
library(svglite)
library(latex2exp)
library(ggnewscale)
### Functions ###
generer_positions <- function(position_centrale, pas, taille) {
positions <- seq(position_centrale - (taille - 1) * pas / 2,
position_centrale + (taille - 1) * pas / 2,
by = pas)
return(positions)
}
### Parameters ###
folder_output_ = folder_output_param_
nomSim_ = nomSim_param_
jourMin_ = jourMin_param_
jourMax_ = jourMax_param_
nom_categorieSimu_ = nom_categorieSimu_param_
nom_apprentissage_ = nom_apprentissage_param_
nom_validation_ = nom_validation_param_
annees_validModels_ = annees_validModels_param_
nom_GCM_ = nom_GCM_param_
breaks_NSE_ = breaks_NSE_param
folder_input_ = folder_input_param_
HER_ = HER_param_
sansTexteHer_ = T
HER2_excluesDensity_ = NULL
### Import HER2 ###
fr.frontieres <- readOGR("/home/tjaouen/Documents/Input/FondsCartes/ContoursAdministratifs/FRA_adm_shp/","FRA_adm0")
proj4string(fr.frontieres)=CRS("+proj=longlat +ellps=WGS84")
fr.frontieres <- spTransform(fr.frontieres, CRS("+init=epsg:2154")) # trasnformation en Lambert93
fr.spdf <- readOGR("/home/tjaouen/Documents/Input/HER/HER2hybrides/Shapefile/","HER2_hybrides")
proj4string(fr.spdf)=CRS("+proj=longlat +ellps=WGS84")
fr.prj <- spTransform(fr.spdf, CRS("+init=epsg:2154")) # trasnformation en Lambert93
### Jonction ###
fr.prj$CdHER2[which(fr.prj$CdHER2 == 37)] = "37+54"
fr.prj$CdHER2[which(fr.prj$CdHER2 == 54)] = "37+54"
fr.prj$CdHER2[which(fr.prj$CdHER2 == 69)] = "69+96"
fr.prj$CdHER2[which(fr.prj$CdHER2 == 96)] = "69+96"
fr.prj$CdHER2[which(fr.prj$CdHER2 == 31)] = "31+33+39"
fr.prj$CdHER2[which(fr.prj$CdHER2 == 33)] = "31+33+39"
fr.prj$CdHER2[which(fr.prj$CdHER2 == 39)] = "31+33+39"
fr.prj$CdHER2[which(fr.prj$CdHER2 == 89)] = "89+92"
fr.prj$CdHER2[which(fr.prj$CdHER2 == 92)] = "89+92"
fr.prj$CdHER2[which(fr.prj$CdHER2 == 49)] = "49+90"
fr.prj$CdHER2[which(fr.prj$CdHER2 == 90)] = "49+90"
HER_[which(HER_ == 31033039)] = "31+33+39"
HER_[which(HER_ == 37054)] = "37+54"
HER_[which(HER_ == 69096)] = "69+96"
HER_[which(HER_ == 89092)] = "89+92"
HER_[which(HER_ == 49090)] = "49+90"
# Legende des HER 2
# Extraire les coordonnées des centres de chaque polygone d'hydroécorégion de niveau 2
her2_centers <- coordinates(gCentroid(fr.prj, byid=TRUE))
# Extraire l'attribut "NUM_HER2" de chaque polygone d'hydroécorégion de niveau 2
her2_attrib <- fr.prj$CdHER2
# Convertir fr.prj en un dataframe utilisable dans ggplot2
fr.df <- fortify(fr.prj)
fr.df <- merge(fr.df, as.data.frame(fr.prj@data), by.x = "id", by.y = "row.names", all = TRUE)
# Coordonnees
unit_x_ = max(fr.df$long) - min(fr.df$long)
unit_y_ = max(fr.df$lat) - min(fr.df$lat)
origin_x_ = min(fr.df$long)
origin_y_ = min(fr.df$lat)
HER_h_
HER_h_=2
fr.df_HER_ = fr.df[which(fr.df$CdHER2 == HER_h_),]
fr.df_HER_$var_cut_ <- "#037398"
p <- ggplot() +
geom_polygon(data=fr.frontieres, aes(x=long, y=lat, group=group), fill = "white",
color="black", linewidth = 1) +
scale_fill_manual(values=c("#ffffff"),
breaks=c("#ffffff"),
drop = F)
p <- ggplot() +
geom_polygon(data=fr.df_HER_, aes(x=long, y=lat, group=group, fill=var_cut_), linewidth = 1)+
scale_fill_manual(values=c("#037398"),
breaks=c("#037398"))+
new_scale_color()+
geom_polygon(data=fr.frontieres, aes(x=long, y=lat, group=group), fill = NA,
color="black", size = 0.3)
if (sansTexteHer_ == FALSE){
p <- p + geom_text(data = data.frame(x = her2_centers[,1], y = her2_centers[,2], label = her2_attrib),
aes(x = x, y = y, label = label),
col = "black", size = 4, segment.alpha = 0.3,
force = 10)
}
p <- p +
theme(axis.line = element_blank(),
axis.text = element_blank(),
axis.ticks = element_blank(),
axis.title = element_blank(),
legend.position = "none",
legend.title = element_blank(),
legend.text = element_blank(),
panel.background = element_blank(),
text = element_text(size = 26),
plot.title = element_text(size = 30, hjust = 0.5))+
coord_fixed(ratio = 1)
# Echelle
p <- p + annotation_scale(location = "bl",
line_width = .8,
text_cex = 0.7,
pad_x = unit(1.5, "cm"), pad_y = unit(2, "cm"),
style = 'ticks')+#,
# text = element_blank()) +
annotation_north_arrow(location = "bl", height = unit(0.7, "cm"), width = unit(0.7, "cm"),
pad_x = unit(1.5, "cm"), pad_y = unit(3, "cm"))
p <- p +
annotate("rect",
xmin = origin_x_ + 0.255 * unit_x_, xmax = origin_x_ + 0.35 * unit_x_,
ymin = origin_y_ + 0 * unit_y_, ymax = origin_y_ + 0.1 * unit_y_, fill = "white")
p <- p + annotate("text",
x = origin_x_ + 0.26 * unit_x_,
y = origin_y_ + 0.034 * unit_y_,
label = TeX("300 km"),
size = 4,
hjust = 0)
p
p <- ggplot() +
geom_polygon(data=fr.df_HER_, aes(x=long, y=lat, group=group, fill=var_cut_), color = "black", linewidth = 1)+
scale_fill_manual(values=c("#037398"),
breaks=c("#037398"))+
new_scale_color()+
geom_polygon(data=fr.frontieres, aes(x=long, y=lat, group=group), fill = NA,
color="black", size = 0.3)
if (sansTexteHer_ == FALSE){
p <- p + geom_text(data = data.frame(x = her2_centers[,1], y = her2_centers[,2], label = her2_attrib),
aes(x = x, y = y, label = label),
col = "black", size = 4, segment.alpha = 0.3,
force = 10)
}
p <- p +
theme(axis.line = element_blank(),
axis.text = element_blank(),
axis.ticks = element_blank(),
axis.title = element_blank(),
legend.position = "none",
legend.title = element_blank(),
legend.text = element_blank(),
panel.background = element_blank(),
text = element_text(size = 26),
plot.title = element_text(size = 30, hjust = 0.5))+
coord_fixed(ratio = 1)
# Echelle
p <- p + annotation_scale(location = "bl",
line_width = .8,
text_cex = 0.7,
pad_x = unit(1.5, "cm"), pad_y = unit(2, "cm"),
style = 'ticks')+#,
# text = element_blank()) +
annotation_north_arrow(location = "bl", height = unit(0.7, "cm"), width = unit(0.7, "cm"),
pad_x = unit(1.5, "cm"), pad_y = unit(3, "cm"))
p <- p +
annotate("rect",
xmin = origin_x_ + 0.255 * unit_x_, xmax = origin_x_ + 0.35 * unit_x_,
ymin = origin_y_ + 0 * unit_y_, ymax = origin_y_ + 0.1 * unit_y_, fill = "white")
p <- p + annotate("text",
x = origin_x_ + 0.26 * unit_x_,
y = origin_y_ + 0.034 * unit_y_,
label = TeX("300 km"),
size = 4,
hjust = 0)
p
p <- ggplot() +
geom_polygon(data=fr.df_HER_, aes(x=long, y=lat, group=group, fill=var_cut_), color = "black", linewidth = 0.3)+
scale_fill_manual(values=c("#037398"),
breaks=c("#037398"))+
new_scale_color()+
geom_polygon(data=fr.frontieres, aes(x=long, y=lat, group=group), fill = NA,
color="black", size = 0.3)
if (sansTexteHer_ == FALSE){
p <- p + geom_text(data = data.frame(x = her2_centers[,1], y = her2_centers[,2], label = her2_attrib),
aes(x = x, y = y, label = label),
col = "black", size = 4, segment.alpha = 0.3,
force = 10)
}
p <- p +
theme(axis.line = element_blank(),
axis.text = element_blank(),
axis.ticks = element_blank(),
axis.title = element_blank(),
legend.position = "none",
legend.title = element_blank(),
legend.text = element_blank(),
panel.background = element_blank(),
text = element_text(size = 26),
plot.title = element_text(size = 30, hjust = 0.5))+
coord_fixed(ratio = 1)
# Echelle
p <- p + annotation_scale(location = "bl",
line_width = .8,
text_cex = 0.7,
pad_x = unit(1.5, "cm"), pad_y = unit(2, "cm"),
style = 'ticks')+#,
# text = element_blank()) +
annotation_north_arrow(location = "bl", height = unit(0.7, "cm"), width = unit(0.7, "cm"),
pad_x = unit(1.5, "cm"), pad_y = unit(3, "cm"))
p <- ggplot() +
geom_polygon(data=fr.frontieres, aes(x=long, y=lat, group=group), fill = "white",
color="black", linewidth = 1) +
scale_fill_manual(values=c("#ffffff"),
breaks=c("#ffffff"),
drop = F)
p <- ggplot() +
geom_polygon(data=fr.df_HER_, aes(x=long, y=lat, group=group, fill=var_cut_), color = "black", linewidth = 0.3)+
scale_fill_manual(values=c("#037398"),
breaks=c("#037398"))+
new_scale_color()+
geom_polygon(data=fr.frontieres, aes(x=long, y=lat, group=group), fill = NA,
color="black", size = 0.3)
if (sansTexteHer_ == FALSE){
p <- p + geom_text(data = data.frame(x = her2_centers[,1], y = her2_centers[,2], label = her2_attrib),
aes(x = x, y = y, label = label),
col = "black", size = 4, segment.alpha = 0.3,
force = 10)
}
p <- p +
theme(axis.line = element_blank(),
axis.text = element_blank(),
axis.ticks = element_blank(),
axis.title = element_blank(),
legend.position = "none",
legend.title = element_blank(),
legend.text = element_blank(),
panel.background = element_blank(),
text = element_text(size = 26),
plot.title = element_text(size = 30, hjust = 0.5))+
coord_fixed(ratio = 1)
# Echelle
p <- p + annotation_scale(location = "bl",
line_width = .8,
text_cex = 0.7,
pad_x = unit(1.5, "cm"), pad_y = unit(2, "cm"),
style = 'ticks')+#,
# text = element_blank()) +
annotation_north_arrow(location = "bl", height = unit(0.7, "cm"), width = unit(0.7, "cm"),
pad_x = unit(1.5, "cm"), pad_y = unit(3, "cm"))
p <- p +
annotate("rect",
xmin = origin_x_ + 0.255 * unit_x_, xmax = origin_x_ + 0.35 * unit_x_,
ymin = origin_y_ + 0 * unit_y_, ymax = origin_y_ + 0.1 * unit_y_, fill = "white")
p <- p + annotate("text",
x = origin_x_ + 0.26 * unit_x_,
y = origin_y_ + 0.034 * unit_y_,
label = TeX("300 km"),
size = 4,
hjust = 0)
p
nom_categorieSimu_
ifelse(nom_categorieSimu_=="","",paste0("/",str_before_first(nom_categorieSimu_,"/")))
nomSim_
nom_categorieSimu_
folder_HER_DataDescription_
folder_input_PC_param_
folder_input_PC_param_
source("/home/tjaouen/Documents/Src/ChangementClimatique_Bottet2019/CodesTristan/8_RunsEtudeFrance_ApresCorrectionNcdfLH/1_Parameters/0_SimulationParameters_AvecCC_2_20230227.R")
source("/home/tjaouen/Documents/Src/PathsProgram/PathProgram_1_20230206.R")
source("/home/tjaouen/Documents/Src/ChangementClimatique_Bottet2019/CodesTristan/8_RunsEtudeFrance_ApresCorrectionNcdfLH/0_GraphesDescriptifsDonnees/0_GraphParameters_1_20230901.R")
suppressMessages(library(doParallel))
suppressMessages(library(tidyverse))
suppressMessages(library(svglite))
suppressMessages(library(ggplot2))
suppressMessages(library(strex))
suppressMessages(library(latex2exp))
suppressMessages(library(lubridate))
### Parameters ###
folder_output_ = folder_output_param_
nomSim_ = nomSim_param_
jourMin_ = jourMin_param_
jourMax_ = jourMax_param_
nom_categorieSimu_ = nom_categorieSimu_param_
nom_apprentissage_ = nom_apprentissage_param_
nom_validation_ = nom_validation_param_
annees_validModels_ = annees_validModels_param_
nom_GCM_ = nom_GCM_param_
breaks_NSE_ = breaks_NSE_param
folder_input_ = folder_input_param_
HER_ = HER_param_
date_intervalle_ = c("2021-01-01","2050-12-31")
pattern_rcp_ = str_before_last(str_after_last(nom_categorieSimu_,"_"),"/")
### Files ###
print(paste0(folder_input_,"Tab_ChroniquesProba_LearnBrut_ByHer/",
ifelse(obsSim_param_=="",nom_GCM_param_,
paste0("FDC_",obsSim_param_,
ifelse(nom_FDCfolder_param_=="","",paste0("_",nom_FDCfolder_param_)),"/",
ifelse(nom_categorieSimu_param_=="","",str_before_first(nom_categorieSimu_param_,"/")),"/"))))
list_files_chroniquesProba_ <- list.files(paste0(folder_input_,"Tab_ChroniquesProba_LearnBrut_ByHer/",
ifelse(obsSim_param_=="",nom_GCM_param_,
paste0("FDC_",obsSim_param_,
ifelse(nom_FDCfolder_param_=="","",paste0("_",nom_FDCfolder_param_)),"/",
ifelse(nom_categorieSimu_param_=="","",nom_categorieSimu_param_),"/"))),
recursive = T,
full.names = T)
nFiles_to_use = length(HER_)
HER_h_ = 71
for (l in 1:length(list_files_chroniquesProba_)){
tab_l_ <- read.table(list_files_chroniquesProba_[l], sep = ";", dec = ".", header = T)
colnames(tab_l_) <- gsub("X","",colnames(tab_l_))
tab_l_ <- tab_l_[,c("Date","Type",HER_h_)]
colnames(tab_l_) <- c("Date","Type",str_after_last(str_before_last(list_files_chroniquesProba_[l],"/"),"/"))
if (ncol(tab_allModels_) == 0){
tab_allModels_ <- tab_l_
}else{
tab_allModels_ <- merge(tab_allModels_, tab_l_, by = c("Date","Type"))
}
}
list_files_chroniquesProba_
list_files_chroniquesProba_ <- list.files(paste0(folder_input_,"Tab_ChroniquesProba_LearnBrut_ByHer/",
ifelse(obsSim_param_=="",nom_GCM_param_,
paste0("FDC_",obsSim_param_,
ifelse(nom_FDCfolder_param_=="","",paste0("_",nom_FDCfolder_param_)),"/",
ifelse(nom_categorieSimu_param_=="","",nom_categorieSimu_param_),"/"))),
recursive = T,
full.names = T)
obsSim_param_
nom_FDCfolder_param_
list_files_chroniquesProba_ <- list.files(paste0(folder_input_,"Tab_ChroniquesProba_LearnBrut_ByHer/",
ifelse(obsSim_param_=="",nom_GCM_param_,
paste0("FDC_",obsSim_param_,
ifelse(nom_FDCfolder_param_=="","",paste0("_",nom_FDCfolder_param_)),"/",
ifelse(nom_categorieSimu_param_=="","",nom_categorieSimu_param_),"/"))),
recursive = T,
full.names = T)
list_files_chroniquesProba_
folder_input_
list_files_chroniquesProba_ <- list.files(paste0(folder_input_,"Tab_ChroniquesProba_LearnBrut_ByHer/",
ifelse(obsSim_param_=="",nom_GCM_param_,
paste0("FDC_",obsSim_param_,
ifelse(nom_FDCfolder_param_=="","",paste0("_",nom_FDCfolder_param_)),"/",
ifelse(nom_categorieSimu_param_=="","",nom_categorieSimu_param_),"/"))),
recursive = T,
full.names = T)
list_files_chroniquesProba_
list_files_chroniquesProba_ <- list.files(paste0(folder_input_,"Tab_ChroniquesProba_LearnBrut_ByHer/",
ifelse(obsSim_param_=="",nom_GCM_param_,
paste0("FDC_",obsSim_param_,
ifelse(nom_FDCfolder_param_=="","",paste0("_",nom_FDCfolder_param_)),"/",
ifelse(nom_categorieSimu_param_=="","",nom_categorieSimu_param_),"/"))),
recursive = T,
full.names = T)
nFiles_to_use = length(HER_)
print(HER_h_)
for (l in 1:length(list_files_chroniquesProba_)){
tab_l_ <- read.table(list_files_chroniquesProba_[l], sep = ";", dec = ".", header = T)
colnames(tab_l_) <- gsub("X","",colnames(tab_l_))
tab_l_ <- tab_l_[,c("Date","Type",HER_h_)]
colnames(tab_l_) <- c("Date","Type",str_after_last(str_before_last(list_files_chroniquesProba_[l],"/"),"/"))
if (ncol(tab_allModels_) == 0){
tab_allModels_ <- tab_l_
}else{
tab_allModels_ <- merge(tab_allModels_, tab_l_, by = c("Date","Type"))
}
}
### Formater ###
tab_allModels_$Date <- as.Date(tab_allModels_$Date)
tab_allModels_$Jour_annee <- format(tab_allModels_$Date, format = "%m-%d")
### Selectionner periode ###
tab_allModels_2070_2100_ = tab_allModels_[which(tab_allModels_$Date >= as.Date(date_intervalle_[1]) & tab_allModels_$Date <= as.Date(date_intervalle_[2])),]
if (!(nrow(tab_allModels_2070_2100_[which(tab_allModels_2070_2100_$Type == "Historical"),]) %in% c(as.Date(date_intervalle_[2])-as.Date(date_intervalle_[1])+1,0))){
stop(paste0("Error with Historical content. File :", list_files_chroniquesProba_[l], " - HER : ", HER_h_))
}
if (!(nrow(tab_allModels_2070_2100_[which(tab_allModels_2070_2100_$Type == "Safran"),]) %in% c(as.Date(date_intervalle_[2])-as.Date(date_intervalle_[1])+1,0))){
stop(paste0("Error with Safran content. File :", list_files_chroniquesProba_[l], " - HER : ", HER_h_))
}
if (!(nrow(tab_allModels_2070_2100_[grepl("rcp",tab_allModels_2070_2100_$Type),]) %in% c(as.Date(date_intervalle_[2])-as.Date(date_intervalle_[1])+1,0))){
stop(paste0("Error with rcp content. File :", list_files_chroniquesProba_[l], " - HER : ", HER_h_))
}
date_intervalle_
max(tab_allModels_$Date)
min(tab_allModels_$Date)
print("J2000 - 8_Chroniques_ProjectionsAssecs_19752004_7local_20240229.R")
source("/lustre/jaouent/Src/ChangementClimatique_Bottet2019/CodesTristan/8_RunsEtudeFrance_ApresCorrectionNcdfLH_MESO/Src_J2000/PathsProgram/PathProgram_1_20230206.R")
source("/home/tjaouen/Documents/Src/ChangementClimatique_Bottet2019/CodesTristan/8_RunsEtudeFrance_ApresCorrectionNcdfLH/1_Parameters/0_SimulationParameters_AvecCC_2_20230227.R")
source("/home/tjaouen/Documents/Src/PathsProgram/PathProgram_1_20230206.R")
source("/home/tjaouen/Documents/Src/ChangementClimatique_Bottet2019/CodesTristan/8_RunsEtudeFrance_ApresCorrectionNcdfLH/0_GraphesDescriptifsDonnees/0_GraphParameters_1_20230901.R")
### Libraries ###
suppressMessages(library(doParallel))
suppressMessages(library(tidyverse))
suppressMessages(library(svglite))
suppressMessages(library(ggplot2))
suppressMessages(library(strex))
suppressMessages(library(latex2exp))
suppressMessages(library(lubridate))
### Parameters ###
folder_output_ = folder_output_param_
nomSim_ = nomSim_param_
jourMin_ = jourMin_param_
jourMax_ = jourMax_param_
nom_categorieSimu_ = nom_categorieSimu_param_
nom_apprentissage_ = nom_apprentissage_param_
nom_validation_ = nom_validation_param_
annees_validModels_ = annees_validModels_param_
nom_GCM_ = nom_GCM_param_
breaks_NSE_ = breaks_NSE_param
folder_input_ = folder_input_param_
HER_ = HER_param_
date_intervalle_ = c("1977-01-01","2004-12-31")
pattern_rcp_ = str_before_last(str_after_last(nom_categorieSimu_,"_"),"/")
### Files ###
print(paste0(folder_input_,"Tab_ChroniquesProba_LearnBrut_ByHer/",
ifelse(obsSim_param_=="",nom_GCM_param_,
paste0("FDC_",obsSim_param_,
ifelse(nom_FDCfolder_param_=="","",paste0("_",nom_FDCfolder_param_)),"/",
ifelse(nom_categorieSimu_=="","",nom_categorieSimu_)))))
list_files_chroniquesProba_ <- list.files(paste0(folder_input_,"Tab_ChroniquesProba_LearnBrut_ByHer/",
ifelse(obsSim_param_=="",nom_GCM_param_,
paste0("FDC_",obsSim_param_,
ifelse(nom_FDCfolder_param_=="","",paste0("_",nom_FDCfolder_param_)),"/",
ifelse(nom_categorieSimu_param_=="","",nom_categorieSimu_param_),"/"))),
recursive = T,
full.names = T)
# list_files_chroniquesProba_ <- list_files_chroniquesProba_[1:2]
nFiles_to_use = length(HER_)
print(HER_h_)
tab_allModels_ = data.frame()
tab_1_ <- read.table(list_files_chroniquesProba_[1], sep = ";", dec = ".", header = T)
colnames(tab_1_) <- gsub("X","",colnames(tab_1_))
for (l in 1:length(list_files_chroniquesProba_)){
tab_l_ <- read.table(list_files_chroniquesProba_[l], sep = ";", dec = ".", header = T)
colnames(tab_l_) <- gsub("X","",colnames(tab_l_))
tab_l_ <- tab_l_[,c("Date","Type",HER_h_)]
colnames(tab_l_) <- c("Date","Type",str_after_last(str_before_last(list_files_chroniquesProba_[l],"/"),"/"))
if (ncol(tab_allModels_) == 0){
tab_allModels_ <- tab_l_
}else{
tab_allModels_ <- merge(tab_allModels_, tab_l_, by = c("Date","Type"))
}
}
### Formater ###
tab_allModels_$Date <- as.Date(tab_allModels_$Date)
tab_allModels_$Jour_annee <- format(tab_allModels_$Date, format = "%m-%d")
### Selectionner periode ###
tab_allModels_2070_2100_ = tab_allModels_[which(tab_allModels_$Date >= as.Date(date_intervalle_[1]) & tab_allModels_$Date <= as.Date(date_intervalle_[2])),]
if (!(nrow(tab_allModels_2070_2100_[which(tab_allModels_2070_2100_$Type == "Historical"),]) %in% c(as.Date(date_intervalle_[2])-as.Date(date_intervalle_[1])+1,0))){
stop(paste0("Error with Historical content. File :", list_files_chroniquesProba_[l], " - HER : ", HER_h_))
}
if (!(nrow(tab_allModels_2070_2100_[which(tab_allModels_2070_2100_$Type == "Safran"),]) %in% c(as.Date(date_intervalle_[2])-as.Date(date_intervalle_[1])+1,0))){
stop(paste0("Error with Safran content. File :", list_files_chroniquesProba_[l], " - HER : ", HER_h_))
}
if (!(nrow(tab_allModels_2070_2100_[grepl("rcp",tab_allModels_2070_2100_$Type),]) %in% c(as.Date(date_intervalle_[2])-as.Date(date_intervalle_[1])+1,0))){
stop(paste0("Error with rcp content. File :", list_files_chroniquesProba_[l], " - HER : ", HER_h_))
}
### Melt (convertir) le dataframe pour le rendre plus facile à utiliser dans ggplot2 ###
df_melted <- tab_allModels_2070_2100_ %>%
select(-Jour_annee) %>%
pivot_longer(cols = -c(Date, Type), names_to = "Variable", values_to = "Value")
nom_categorieSimu_param_
nom_apprentissage_param_
